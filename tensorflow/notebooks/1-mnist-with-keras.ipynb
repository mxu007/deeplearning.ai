{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-mnist-with-keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mxu007/deeplearning.ai/blob/master/tensorflow/notebooks/1-mnist-with-keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "IZrAitlFLdEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST with tf.keras\n",
        "\n",
        "Welcome! In this lab, you'll learn how to train an image classifier train on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) - the \"hello world\" of computer vision. You'll go through all the steps, including loading the data, building and training a model, calculating the accuracy, and making predictions. Our focus here is on the code. For more on any of the concepts below, see [https://ai.google/education](https://ai.google/education)."
      ]
    },
    {
      "metadata": {
        "id": "jSmUsjJfMEqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a34f7c73-5a71-4861-db3a-ce79e07b0251"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q -U tensorflow==1.8.0\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8Lhscw0NDln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1: Download the dataset\n",
        "\n",
        "The MNIST dataset contains thousands of grayscale images of handwritten digits."
      ]
    },
    {
      "metadata": {
        "id": "FKiwTuT-NE6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e880f2ba-6f75-4adb-8b08-3d343b42899b"
      },
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eEFU58MaNPpk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2) Visualize the data\n",
        "Let's see how the images look. This function shows a random example along with it's corresponding label."
      ]
    },
    {
      "metadata": {
        "id": "AwxNOsCMNNGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "34441c36-2961-49b2-f3f2-97be9c961497"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "i = random.randint(0, 100)\n",
        "\n",
        "print(\"Label: %s\" % train_labels[i])\n",
        "plt.imshow(train_images[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcf060c7ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcf0e3f6750>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "e2n2NVdKNk5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3) Understand the data format\n",
        "\n",
        "We are given the images as a 3-D array of integer values that is of shape (*N*, 28, 28), where *N* is the number of images in the training or test set. The labels are 1-D array of the integer values of each image."
      ]
    },
    {
      "metadata": {
        "id": "TTj2ZWMBN24i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5f04087b-9228-4542-8f98-bbf54c157d96"
      },
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eo_cZXaqODnZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4) Reformat the images\n",
        "Here, we'll flatten (or unstack) the images. There are deep learning techniques that work with 2d images directly (rather than their flattened representation), but we'll start with this format. Instead of working with a 28 by 28 *image*, we'll unstack it into a 28 \\* 28 = 784 length *array*.\n",
        "\n",
        "* We want to convert the 3-D array of shape (*N*, 28, 28) to a 2-D array of shape (*N*, 784) where the second dimension is just an array of all the pixels in an image. This is called flattening, or unstacking, the images. \n",
        "* We also want to convert the pixel values from a number between 0 and 255 to a number between 0 and 1."
      ]
    },
    {
      "metadata": {
        "id": "OgnV5FJjP5Vz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "10a5da88-1450-4104-8cdf-14826aab6dfe"
      },
      "cell_type": "code",
      "source": [
        "TRAINING_SIZE = len(train_images)\n",
        "TEST_SIZE = len(test_images)\n",
        "\n",
        "# Reshape from (N, 28, 28) to (N, 784)\n",
        "train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n",
        "test_images = np.reshape(test_images, (TEST_SIZE, 784))\n",
        "\n",
        "# Convert the array to float32 as opposed to uint8\n",
        "train_images = train_images.astype(np.float32)\n",
        "test_images = test_images.astype(np.float32)\n",
        "\n",
        "# Convert the pixel values from integers between 0 and 255 to floats between 0 and 1\n",
        "train_images /= 255\n",
        "test_images /=  255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GI25z0StQH-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5) Reformat the labels\n",
        "\n",
        "Next, we want to convert the labels from an integer format (e.g., \"2\"), to a [one hot encoding](https://en.wikipedia.org/wiki/One-hot) (e.g., \"0, 0, 1, 0, 0, 0, 0, 0, 0, 0\"). To do so, we'll use the `tf.keras.utils.to_categorical` [function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) function."
      ]
    },
    {
      "metadata": {
        "id": "E9yrkEENQ9Vz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8cc6608f-485c-456c-9060-123dcf4ea068"
      },
      "cell_type": "code",
      "source": [
        "NUM_DIGITS = 10\n",
        "\n",
        "print(\"Before\", train_labels[0]) # The format of the labels before conversion\n",
        "\n",
        "train_labels  = tf.keras.utils.to_categorical(train_labels, NUM_DIGITS)\n",
        "\n",
        "print(\"After\", train_labels[0]) # The format of the labels after conversion\n",
        "\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, NUM_DIGITS)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Before', 5)\n",
            "('After', array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pjdbemHURkpv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 6) Build the model\n",
        "\n",
        "Now, we'll create our neural network using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). \n",
        "* Architecture wise, we'll single layer network. \n",
        "* The hidden layer will have 512 units using the [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu) activation function. \n",
        "* The output layer will have 10 units and use [softmax](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax) function. \n",
        "* Notice, we specify the input shape on the first layer. If you add subsequent layers, this is not necessary. \n",
        "* We will use the [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy) loss function, and the [RMSProp](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop) optimizer."
      ]
    },
    {
      "metadata": {
        "id": "mNscbvHkUrMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "860aeeeb-975d-462f-dddf-202c6b4dbce3"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "# We will now compile and print out a summary of our model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k3br9Yi6VuBT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 7) Training\n",
        "\n",
        "Next, we will train the model by using the [fit method](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit) for 5 [epochs](https://www.quora.com/What-is-epochs-in-machine-learning). We will keep track of the training loss and accuracy as we go. Please be patient as this step may take a while depending on your hardware."
      ]
    },
    {
      "metadata": {
        "id": "gBs0LwqcVXx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "67eeea3c-1e4d-40b8-9a5f-03c74ee4ab75"
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 16s 268us/step - loss: 0.2050 - acc: 0.9396\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 16s 260us/step - loss: 0.0910 - acc: 0.9737\n",
            "Epoch 3/5\n",
            "10240/60000 [====>.........................] - ETA: 13s - loss: 0.0556 - acc: 0.9848"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 16s 264us/step - loss: 0.0671 - acc: 0.9816\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.0527 - acc: 0.9858\n",
            "Epoch 5/5\n",
            "18560/60000 [========>.....................] - ETA: 10s - loss: 0.0385 - acc: 0.9895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 15s 257us/step - loss: 0.0420 - acc: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fcf060581d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "zofRrQJk9Sgg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What is the use of train_on_batch() in keras?**\n",
        "\n",
        "\n",
        "I believe you mean to compare train_on_batch with fit (and variations like fit_generator), since train is not a commonly available API function for Keras.\n",
        "\n",
        "For this question, it's a simple answer from the primary author:\n",
        "\n",
        "With fit_generator, you can use a generator for the validation data as well. In general I would recommend using fit_generator, but using train_on_batch works fine too. These methods only exist as for the sake of convenience in different use cases, there is no \"correct\" method.\n",
        "\n",
        "train_on_batch allows you to expressly update weights based on a collection of samples you provide, without regard to any fixed batch size. You would use this in cases when that is what you want: to train on an explicit collection of samples. You could use that approach to maintain your own iteration over multiple batches of a traditional training set but allowing fit or fit_generator to iterate batches for you is likely simpler.\n",
        "\n",
        "One case when it might be nice to use train_on_batch is for updating a pre-trained model on a single new batch of samples. Suppose you've already trained and deployed a model, and sometime later you've received a new set of training samples previously never used. You could use train_on_batch to directly update the existing model only on those samples. Other methods can do this too, but it is rather explicit to use train_on_batch for this case.\n",
        "\n",
        "Apart from special cases like this (either where you have some pedagogical reason to maintain your own cursor across different training batches, or else for some type of semi-online training update on a special batch), it is probably better to just always use fit (for data that fits in memory) or fit_generator (for streaming batches of data as a generator)."
      ]
    },
    {
      "metadata": {
        "id": "rcYMPkwkWIPq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 8) Testing\n",
        "Now that we have trained our model, we want to evaluate it. Sure, our model is >97% accurate on the training set, but what about on data it hasn't seen before? The test accuracy is a good metric for that."
      ]
    },
    {
      "metadata": {
        "id": "iuqDe4NiWBpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d75cac5-d4d2-4bd6-954d-3d5c03bc0b01"
      },
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy: %.2f' % (accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 62us/step\n",
            "Test accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jo-yoMwvXkw6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Congratulations\n",
        "You have successfully used TensorFlow Keras to train a model on the MNIST dataset."
      ]
    }
  ]
}