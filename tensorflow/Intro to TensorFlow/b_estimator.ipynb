{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>2b. Machine Learning using tf.estimator </h1>\n",
    "\n",
    "In this notebook, we will create a machine learning model using tf.estimator and evaluate its performance.  The dataset is rather small (7700 samples), so we can do it all in-memory.  We will also simply pass the raw data in as-is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Read data created in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In CSV, label is the first column, after the features, followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "df_train = pd.read_csv('./taxi-train.csv', header = None, names = CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('./taxi-valid.csv', header = None, names = CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Input functions to read from Pandas Dataframe </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our input function for predictions is the same except we don't provide a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_prediction_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = None,\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create feature columns for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb968989790>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'taxi_trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 23958.61, step = 1\n",
      "INFO:tensorflow:global_step/sec: 298.999\n",
      "INFO:tensorflow:loss = 9268.811, step = 101 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.545\n",
      "INFO:tensorflow:loss = 7180.4575, step = 201 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.283\n",
      "INFO:tensorflow:loss = 7978.928, step = 301 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.425\n",
      "INFO:tensorflow:loss = 15105.782, step = 401 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.459\n",
      "INFO:tensorflow:loss = 7852.948, step = 501 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.534\n",
      "INFO:tensorflow:loss = 5799.3926, step = 601 (0.270 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 608 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 140.74872.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7fb968989810>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Evaluate on the validation data (we should defer using the test data to after we have selected a final model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-08-14:01:53\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-08-14:01:53\n",
      "INFO:tensorflow:Saving dict for global step 608: average_loss = 109.88187, global_step = 608, loss = 13068.094\n",
      "RMSE on validation dataset = 10.4824552536\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, name, df):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(df, 1))\n",
    "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is nowhere near our benchmark (RMSE of $6 or so on this data), but it serves to demonstrate what TensorFlow code looks like.  Let's use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'predictions': array([10.601626], dtype=float32)}\n",
      "{'predictions': array([10.59816], dtype=float32)}\n",
      "{'predictions': array([10.601273], dtype=float32)}\n",
      "{'predictions': array([10.796947], dtype=float32)}\n",
      "{'predictions': array([10.695478], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(input_fn = make_prediction_input_fn(df_valid, 1))\n",
    "for i in xrange(5):\n",
    "  print(predictions.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This explains why the RMSE was so high -- the model essentially predicts the same amount for every trip.  Would a more complex model help? Let's try using a deep neural network.  The code to do this is quite straightforward as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb929f1b110>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'taxi_trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 27502.82, step = 1\n",
      "INFO:tensorflow:global_step/sec: 270.731\n",
      "INFO:tensorflow:loss = 17249.309, step = 101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.287\n",
      "INFO:tensorflow:loss = 21337.71, step = 201 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.228\n",
      "INFO:tensorflow:loss = 23066.078, step = 301 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.616\n",
      "INFO:tensorflow:loss = 16854.602, step = 401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.771\n",
      "INFO:tensorflow:loss = 21270.666, step = 501 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.914\n",
      "INFO:tensorflow:loss = 17826.85, step = 601 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.788\n",
      "INFO:tensorflow:loss = 22209.254, step = 701 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.447\n",
      "INFO:tensorflow:loss = 16418.434, step = 801 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.691\n",
      "INFO:tensorflow:loss = 13816.018, step = 901 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.416\n",
      "INFO:tensorflow:loss = 8276.674, step = 1001 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.639\n",
      "INFO:tensorflow:loss = 20709.836, step = 1101 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.928\n",
      "INFO:tensorflow:loss = 14819.904, step = 1201 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.141\n",
      "INFO:tensorflow:loss = 30821.217, step = 1301 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.605\n",
      "INFO:tensorflow:loss = 20199.992, step = 1401 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.118\n",
      "INFO:tensorflow:loss = 13063.419, step = 1501 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.94\n",
      "INFO:tensorflow:loss = 15399.698, step = 1601 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.003\n",
      "INFO:tensorflow:loss = 21842.355, step = 1701 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.196\n",
      "INFO:tensorflow:loss = 15947.898, step = 1801 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.566\n",
      "INFO:tensorflow:loss = 16963.469, step = 1901 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.639\n",
      "INFO:tensorflow:loss = 22311.11, step = 2001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.811\n",
      "INFO:tensorflow:loss = 18535.906, step = 2101 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.432\n",
      "INFO:tensorflow:loss = 24297.29, step = 2201 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.277\n",
      "INFO:tensorflow:loss = 17513.19, step = 2301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.708\n",
      "INFO:tensorflow:loss = 15430.232, step = 2401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.418\n",
      "INFO:tensorflow:loss = 16696.5, step = 2501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.95\n",
      "INFO:tensorflow:loss = 13577.311, step = 2601 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.939\n",
      "INFO:tensorflow:loss = 11758.636, step = 2701 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.114\n",
      "INFO:tensorflow:loss = 13111.109, step = 2801 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.972\n",
      "INFO:tensorflow:loss = 11288.7, step = 2901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.486\n",
      "INFO:tensorflow:loss = 10019.701, step = 3001 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.212\n",
      "INFO:tensorflow:loss = 13326.32, step = 3101 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.273\n",
      "INFO:tensorflow:loss = 10506.724, step = 3201 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.783\n",
      "INFO:tensorflow:loss = 18178.422, step = 3301 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.942\n",
      "INFO:tensorflow:loss = 18407.238, step = 3401 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.338\n",
      "INFO:tensorflow:loss = 15236.672, step = 3501 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.387\n",
      "INFO:tensorflow:loss = 10938.977, step = 3601 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.266\n",
      "INFO:tensorflow:loss = 12298.624, step = 3701 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.711\n",
      "INFO:tensorflow:loss = 20732.762, step = 3801 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.596\n",
      "INFO:tensorflow:loss = 18808.008, step = 3901 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.39\n",
      "INFO:tensorflow:loss = 12544.807, step = 4001 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.136\n",
      "INFO:tensorflow:loss = 10523.185, step = 4101 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.455\n",
      "INFO:tensorflow:loss = 8617.255, step = 4201 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.555\n",
      "INFO:tensorflow:loss = 12164.723, step = 4301 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.043\n",
      "INFO:tensorflow:loss = 9070.345, step = 4401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.027\n",
      "INFO:tensorflow:loss = 12218.64, step = 4501 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.97\n",
      "INFO:tensorflow:loss = 15602.474, step = 4601 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.599\n",
      "INFO:tensorflow:loss = 10384.906, step = 4701 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.746\n",
      "INFO:tensorflow:loss = 16730.684, step = 4801 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.835\n",
      "INFO:tensorflow:loss = 15744.244, step = 4901 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.97\n",
      "INFO:tensorflow:loss = 13009.674, step = 5001 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.796\n",
      "INFO:tensorflow:loss = 15030.081, step = 5101 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.709\n",
      "INFO:tensorflow:loss = 11151.006, step = 5201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.307\n",
      "INFO:tensorflow:loss = 17930.104, step = 5301 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.687\n",
      "INFO:tensorflow:loss = 14896.129, step = 5401 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.857\n",
      "INFO:tensorflow:loss = 8622.249, step = 5501 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.873\n",
      "INFO:tensorflow:loss = 8112.844, step = 5601 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.967\n",
      "INFO:tensorflow:loss = 12489.115, step = 5701 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.727\n",
      "INFO:tensorflow:loss = 23798.65, step = 5801 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.908\n",
      "INFO:tensorflow:loss = 12232.209, step = 5901 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.307\n",
      "INFO:tensorflow:loss = 8396.75, step = 6001 (0.306 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6071 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2764.3713.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-08-14:02:13\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-08-14:02:14\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 134.9472, global_step = 6071, loss = 16049.078\n",
      "RMSE on validation dataset = 11.6166782379\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 100));\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We are not beating our benchmark with either model ... what's up?  Well, we may be using TensorFlow for Machine Learning, but we are not yet using it well.  That's what the rest of this course is about!\n",
    "\n",
    "But, for the record, let's say we had to choose between the two models. We'd choose the one with the lower validation error. Finally, we'd measure the RMSE on the test data with this chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Benchmark dataset </h2>\n",
    "\n",
    "Let's do this on the benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1 = train 2 = valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  CONCAT(STRING(pickup_datetime), STRING(pickup_longitude), STRING(pickup_latitude), STRING(dropoff_latitude), STRING(dropoff_longitude)) AS key,\n",
    "  DAYOFWEEK(pickup_datetime)*1.0 AS dayofweek,\n",
    "  HOUR(pickup_datetime)*1.0 AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count*1.0 AS passengers,\n",
    "FROM\n",
    "  [nyc-tlc:yellow.trips]\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 < 2\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 == {1}\".format(base_query, phase)\n",
    "  else:\n",
    "    query = \"{0} AND ABS(HASH(pickup_datetime)) % {1} == {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "df = bq.Query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-08-14:02:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-08-14:02:26\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 111.412285, global_step = 6071, loss = 14160.787\n",
      "RMSE on benchmark dataset = 10.5552015305\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model, 'benchmark', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "RMSE on benchmark dataset is <b>9.41</b> (your results will vary because of random seeds).\n",
    "\n",
    "This is not only way more than our original benchmark of 6.00, but it doesn't even beat our distance-based rule's RMSE of 8.02.\n",
    "\n",
    "Fear not -- you have learned how to write a TensorFlow model, but not to do all the things that you will have to do to your ML model performant. We will do this in the next chapters. In this chapter though, we will get our TensorFlow model ready for these improvements.\n",
    "\n",
    "In a software sense, the rest of the labs in this chapter will be about refactoring the code so that we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Simulate the necessary training dataset.\n",
    "<p>\n",
    "Hint (highlight to see):\n",
    "<p style='color:white'>\n",
    "The input features will be r and h and the label will be $\\pi r^2 h$\n",
    "Create random values for r and h and compute V.\n",
    "Your dataset will consist of r, h and V.\n",
    "Then, use a DNN regressor.\n",
    "Make sure to generate enough data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 3)\n",
      "(500, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>h</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210.459585</td>\n",
       "      <td>1.109478</td>\n",
       "      <td>1.543854e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>775.329488</td>\n",
       "      <td>286.847433</td>\n",
       "      <td>5.417182e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>943.902038</td>\n",
       "      <td>25.624870</td>\n",
       "      <td>7.172415e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.813089</td>\n",
       "      <td>778.013487</td>\n",
       "      <td>1.504869e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.172562</td>\n",
       "      <td>340.853040</td>\n",
       "      <td>1.927722e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>903.006249</td>\n",
       "      <td>436.056838</td>\n",
       "      <td>1.117055e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>281.312585</td>\n",
       "      <td>917.401849</td>\n",
       "      <td>2.280803e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>335.330739</td>\n",
       "      <td>164.794105</td>\n",
       "      <td>5.821545e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>436.833289</td>\n",
       "      <td>254.146281</td>\n",
       "      <td>1.523579e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>574.002320</td>\n",
       "      <td>86.521962</td>\n",
       "      <td>8.955782e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>514.524097</td>\n",
       "      <td>310.861410</td>\n",
       "      <td>2.585402e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>845.834386</td>\n",
       "      <td>551.576562</td>\n",
       "      <td>1.239728e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>109.006883</td>\n",
       "      <td>410.109800</td>\n",
       "      <td>1.530939e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>751.564887</td>\n",
       "      <td>415.090518</td>\n",
       "      <td>7.365897e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>127.301757</td>\n",
       "      <td>54.751520</td>\n",
       "      <td>2.787500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>679.076605</td>\n",
       "      <td>559.174730</td>\n",
       "      <td>8.100931e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>340.106561</td>\n",
       "      <td>746.406980</td>\n",
       "      <td>2.712412e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>802.968326</td>\n",
       "      <td>704.881420</td>\n",
       "      <td>1.427785e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>903.322618</td>\n",
       "      <td>106.205898</td>\n",
       "      <td>2.722603e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>216.845797</td>\n",
       "      <td>173.114003</td>\n",
       "      <td>2.557314e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>463.639158</td>\n",
       "      <td>727.989446</td>\n",
       "      <td>4.916264e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>359.498738</td>\n",
       "      <td>17.370531</td>\n",
       "      <td>7.052737e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32.345663</td>\n",
       "      <td>868.908089</td>\n",
       "      <td>2.855984e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>106.248591</td>\n",
       "      <td>527.282849</td>\n",
       "      <td>1.869993e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>407.758525</td>\n",
       "      <td>362.646319</td>\n",
       "      <td>1.894258e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>122.644869</td>\n",
       "      <td>118.072046</td>\n",
       "      <td>5.579506e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>379.074412</td>\n",
       "      <td>932.944899</td>\n",
       "      <td>4.211675e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>854.331939</td>\n",
       "      <td>267.156105</td>\n",
       "      <td>6.125877e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>553.141207</td>\n",
       "      <td>465.363302</td>\n",
       "      <td>4.473156e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>618.510263</td>\n",
       "      <td>121.567680</td>\n",
       "      <td>1.461039e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>892.547955</td>\n",
       "      <td>546.282408</td>\n",
       "      <td>1.367194e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>688.955621</td>\n",
       "      <td>180.821153</td>\n",
       "      <td>2.696383e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>473.299631</td>\n",
       "      <td>667.579791</td>\n",
       "      <td>4.698134e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>655.515359</td>\n",
       "      <td>186.541396</td>\n",
       "      <td>2.518204e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>144.465941</td>\n",
       "      <td>688.538754</td>\n",
       "      <td>4.514495e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>992.522203</td>\n",
       "      <td>684.652821</td>\n",
       "      <td>2.118853e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>421.004890</td>\n",
       "      <td>224.911492</td>\n",
       "      <td>1.252379e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>110.738221</td>\n",
       "      <td>310.098990</td>\n",
       "      <td>1.194663e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>655.490039</td>\n",
       "      <td>111.382503</td>\n",
       "      <td>1.503485e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>699.469115</td>\n",
       "      <td>254.982390</td>\n",
       "      <td>3.919197e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>281.641727</td>\n",
       "      <td>625.662633</td>\n",
       "      <td>1.559136e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>273.588174</td>\n",
       "      <td>6.163355</td>\n",
       "      <td>1.449311e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>929.471623</td>\n",
       "      <td>854.940665</td>\n",
       "      <td>2.320375e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>593.358292</td>\n",
       "      <td>15.517047</td>\n",
       "      <td>1.716299e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>860.905449</td>\n",
       "      <td>31.868212</td>\n",
       "      <td>7.420249e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>592.729770</td>\n",
       "      <td>966.333122</td>\n",
       "      <td>1.066572e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>904.379554</td>\n",
       "      <td>801.068624</td>\n",
       "      <td>2.058359e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>258.024004</td>\n",
       "      <td>793.825470</td>\n",
       "      <td>1.660333e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>322.501382</td>\n",
       "      <td>273.949596</td>\n",
       "      <td>8.951250e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>917.204396</td>\n",
       "      <td>776.288036</td>\n",
       "      <td>2.051658e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>678.041425</td>\n",
       "      <td>258.432160</td>\n",
       "      <td>3.732578e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>177.430561</td>\n",
       "      <td>499.629609</td>\n",
       "      <td>4.941456e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>800.007599</td>\n",
       "      <td>140.656961</td>\n",
       "      <td>2.828130e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>779.187439</td>\n",
       "      <td>553.392576</td>\n",
       "      <td>1.055522e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>597.891530</td>\n",
       "      <td>707.219171</td>\n",
       "      <td>7.942344e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>206.609714</td>\n",
       "      <td>294.909392</td>\n",
       "      <td>3.954940e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>429.128501</td>\n",
       "      <td>865.407315</td>\n",
       "      <td>5.006626e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>72.620405</td>\n",
       "      <td>412.854944</td>\n",
       "      <td>6.840135e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>320.913267</td>\n",
       "      <td>216.757643</td>\n",
       "      <td>7.012932e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>949.549201</td>\n",
       "      <td>564.260193</td>\n",
       "      <td>1.598322e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               r           h             V\n",
       "0     210.459585    1.109478  1.543854e+05\n",
       "1     775.329488  286.847433  5.417182e+08\n",
       "2     943.902038   25.624870  7.172415e+07\n",
       "3      24.813089  778.013487  1.504869e+06\n",
       "4     134.172562  340.853040  1.927722e+07\n",
       "5     903.006249  436.056838  1.117055e+09\n",
       "6     281.312585  917.401849  2.280803e+08\n",
       "7     335.330739  164.794105  5.821545e+07\n",
       "8     436.833289  254.146281  1.523579e+08\n",
       "9     574.002320   86.521962  8.955782e+07\n",
       "10    514.524097  310.861410  2.585402e+08\n",
       "11    845.834386  551.576562  1.239728e+09\n",
       "12    109.006883  410.109800  1.530939e+07\n",
       "13    751.564887  415.090518  7.365897e+08\n",
       "14    127.301757   54.751520  2.787500e+06\n",
       "15    679.076605  559.174730  8.100931e+08\n",
       "16    340.106561  746.406980  2.712412e+08\n",
       "17    802.968326  704.881420  1.427785e+09\n",
       "18    903.322618  106.205898  2.722603e+08\n",
       "19    216.845797  173.114003  2.557314e+07\n",
       "20    463.639158  727.989446  4.916264e+08\n",
       "21    359.498738   17.370531  7.052737e+06\n",
       "22     32.345663  868.908089  2.855984e+06\n",
       "23    106.248591  527.282849  1.869993e+07\n",
       "24    407.758525  362.646319  1.894258e+08\n",
       "25    122.644869  118.072046  5.579506e+06\n",
       "26    379.074412  932.944899  4.211675e+08\n",
       "27    854.331939  267.156105  6.125877e+08\n",
       "28    553.141207  465.363302  4.473156e+08\n",
       "29    618.510263  121.567680  1.461039e+08\n",
       "...          ...         ...           ...\n",
       "1070  892.547955  546.282408  1.367194e+09\n",
       "1071  688.955621  180.821153  2.696383e+08\n",
       "1072  473.299631  667.579791  4.698134e+08\n",
       "1073  655.515359  186.541396  2.518204e+08\n",
       "1074  144.465941  688.538754  4.514495e+07\n",
       "1075  992.522203  684.652821  2.118853e+09\n",
       "1076  421.004890  224.911492  1.252379e+08\n",
       "1077  110.738221  310.098990  1.194663e+07\n",
       "1078  655.490039  111.382503  1.503485e+08\n",
       "1079  699.469115  254.982390  3.919197e+08\n",
       "1080  281.641727  625.662633  1.559136e+08\n",
       "1081  273.588174    6.163355  1.449311e+06\n",
       "1082  929.471623  854.940665  2.320375e+09\n",
       "1083  593.358292   15.517047  1.716299e+07\n",
       "1084  860.905449   31.868212  7.420249e+07\n",
       "1085  592.729770  966.333122  1.066572e+09\n",
       "1086  904.379554  801.068624  2.058359e+09\n",
       "1087  258.024004  793.825470  1.660333e+08\n",
       "1088  322.501382  273.949596  8.951250e+07\n",
       "1089  917.204396  776.288036  2.051658e+09\n",
       "1090  678.041425  258.432160  3.732578e+08\n",
       "1091  177.430561  499.629609  4.941456e+07\n",
       "1092  800.007599  140.656961  2.828130e+08\n",
       "1093  779.187439  553.392576  1.055522e+09\n",
       "1094  597.891530  707.219171  7.942344e+08\n",
       "1095  206.609714  294.909392  3.954940e+07\n",
       "1096  429.128501  865.407315  5.006626e+08\n",
       "1097   72.620405  412.854944  6.840135e+06\n",
       "1098  320.913267  216.757643  7.012932e+07\n",
       "1099  949.549201  564.260193  1.598322e+09\n",
       "\n",
       "[1100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_COLUMNS = ['r', 'h','V']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 64,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )\n",
    "\n",
    "def make_prediction_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = None,\n",
    "    batch_size = 64,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )\n",
    "\n",
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "  return input_columns\n",
    "\n",
    "def print_rmse(model, name, df):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(df, 1))\n",
    "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb920a39e10>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'volume_trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into volume_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 15381275.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 409.715\n",
      "INFO:tensorflow:loss = 9666391.0, step = 101 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.981\n",
      "INFO:tensorflow:loss = 9816910.0, step = 201 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.645\n",
      "INFO:tensorflow:loss = 7199195.0, step = 301 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.67\n",
      "INFO:tensorflow:loss = 7457509.0, step = 401 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.77\n",
      "INFO:tensorflow:loss = 6280342.0, step = 501 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.211\n",
      "INFO:tensorflow:loss = 8583951.0, step = 601 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.521\n",
      "INFO:tensorflow:loss = 8314096.0, step = 701 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.743\n",
      "INFO:tensorflow:loss = 8265142.5, step = 801 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.169\n",
      "INFO:tensorflow:loss = 6122310.0, step = 901 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.727\n",
      "INFO:tensorflow:loss = 6744698.5, step = 1001 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.082\n",
      "INFO:tensorflow:loss = 4615100.0, step = 1101 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.845\n",
      "INFO:tensorflow:loss = 6263886.0, step = 1201 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.641\n",
      "INFO:tensorflow:loss = 5450721.5, step = 1301 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.676\n",
      "INFO:tensorflow:loss = 5250897.5, step = 1401 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.785\n",
      "INFO:tensorflow:loss = 4948007.0, step = 1501 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.983\n",
      "INFO:tensorflow:loss = 6533367.5, step = 1601 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.407\n",
      "INFO:tensorflow:loss = 6169933.5, step = 1701 (0.192 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1719 into volume_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4066914.0.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-08-14:02:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from volume_trained/model.ckpt-1719\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-08-14:02:31\n",
      "INFO:tensorflow:Saving dict for global step 1719: average_loss = 91441.33, global_step = 1719, loss = 5715083.0\n",
      "RMSE on validation dataset = 302.392669678\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "OUTDIR = 'volume_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [64, 16, 2],\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 100));\n",
    "print_rmse(model, 'validation', df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
